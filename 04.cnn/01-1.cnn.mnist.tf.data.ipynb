{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST convolutional neural networks\n",
    "\n",
    "* MNIST data를 가지고 **convolutional neural networks**를 만들어보자.\n",
    "* reference codes\n",
    "  * [tensorflow/tutorials/mnist_deep.py](https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/examples/tutorials/mnist/mnist_deep.py)\n",
    "  * [cs20/examples/07_convnet_mnist.py](https://github.com/chiphuyen/stanford-tensorflow-tutorials/blob/master/examples/07_convnet_mnist.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A very simple MNIST classifier.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 100\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index])\n",
    "plt.colorbar()\n",
    "plt.gca().grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset with `tf.data`\n",
    "\n",
    "### create input pipeline with `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n",
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(219)\n",
    "batch_size = 32\n",
    "max_epochs = 1\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 10000)\n",
    "train_dataset = train_dataset.repeat(count = max_epochs)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.batch(batch_size = len(test_data))\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle,\n",
    "                                               train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "images, labels = iterator.get_next()\n",
    "images = tf.cast(images, dtype = tf.float32)\n",
    "labels = tf.cast(labels, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnMNIST(object):\n",
    "  def __init__(self, inputs, labels):\n",
    "    self.inputs = inputs\n",
    "    self.labels = labels    \n",
    "    self.num_classes = 10\n",
    "    \n",
    "  def inference(self, inputs):\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "    # TODO\n",
    "    self.inputs_images = tf.reshape(self.inputs, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # TODO\n",
    "    conv1 = tf.layers.conv2d(inputs=self.inputs_images, \n",
    "                             filters=32, kernel_size=[5,5], padding='SAME', \n",
    "                             activation=tf.nn.relu, name='conv1')\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # TODO\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1,\n",
    "                                   pool_size=[2,2], padding='SAME',\n",
    "                                   strides=2, name='pool')\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # TODO\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=64,\n",
    "                            kernel_size=[5,5], padding='SAME',\n",
    "                            activation=tf.nn.relu, name='conv2')\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # TODO\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2,2], strides=2, name='pool2')\n",
    "\n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 1024 neurons\n",
    "    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    # TODO\n",
    "    dense = tf.layers.dense(pool2, 1024, activation=tf.nn.relu, name='fc')\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    self.is_training = tf.placeholder(tf.bool)\n",
    "    self.keep_prob = tf.constant(0.6)    \n",
    "    # TODO\n",
    "    dropout = tf.layers.dropout(dense, self.keep_prob, training=self.is_training, name='dropout')\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    # TODO\n",
    "    logits = tf.layers.dense(dropout, self.num_classes, name='logits')\n",
    "\n",
    "    return logits\n",
    "  \n",
    "  def cross_entropy_loss(self, labels, logits):\n",
    "    #y_one_hot = tf.one_hot(y, depth=10)\n",
    "    #cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=y_pred)\n",
    "    cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits, scope='loss')    \n",
    "    \n",
    "    return cross_entropy\n",
    "  \n",
    "  def predictions(self):\n",
    "    with tf.variable_scope('predictions'):\n",
    "      predictions = tf.argmax(self.logits, 1)\n",
    "      \n",
    "      return predictions\n",
    "      \n",
    "  \n",
    "  def build(self):\n",
    "    self.global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    self.logits = self.inference(self.inputs)\n",
    "    self.loss = self.cross_entropy_loss(self.labels, self.logits)\n",
    "    self.predictions = self.predictions()\n",
    "    \n",
    "    print(\"complete model build.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 1) should equal rank of logits minus 1 (received 4).",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-28aadd69a246>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCnnMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# show info for trainable variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mt_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-9a07944c7f65>\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-9a07944c7f65>\u001b[0m in \u001b[0;36mcross_entropy_loss\u001b[1;34m(self, labels, logits)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m#y_one_hot = tf.one_hot(y, depth=10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m#cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mcross_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy\u001b[1;34m(labels, logits, weights, scope, loss_collection, reduction)\u001b[0m\n\u001b[0;32m    913\u001b[0m     losses = nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n\u001b[0;32m    914\u001b[0m                                                          \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m                                                          name=\"xentropy\")\n\u001b[0m\u001b[0;32m    916\u001b[0m     return compute_weighted_loss(\n\u001b[0;32m    917\u001b[0m         losses, weights, scope, loss_collection, reduction=reduction)\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   2051\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[0;32m   2052\u001b[0m                        \u001b[1;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2053\u001b[1;33m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[0;32m   2054\u001b[0m     if (static_shapes_fully_defined and\n\u001b[0;32m   2055\u001b[0m         labels_static_shape != logits.get_shape()[:-1]):\n",
      "\u001b[1;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 1) should equal rank of logits minus 1 (received 4)."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model = CnnMNIST(images, labels)\n",
    "model.build()\n",
    "\n",
    "# show info for trainable variables\n",
    "t_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(t_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(model.loss, global_step=model.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign `tf.summary.FileWriter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_location = 'graphs/01.cnn.mnist.tf.data'\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "  tf.summary.scalar('loss/cross_entropy', model.loss)\n",
    "  tf.summary.image('images', model.inputs_images)\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "  # merge all summaries\n",
    "  summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.Session()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Session start!\")\n",
    "start_time = time.time()\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train_iterator\n",
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "duration = time.time() - start_time\n",
    "print(\"elapsed time making train data: {} sec\".format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training start!\")\n",
    "while True:\n",
    "  try:\n",
    "    start_time = time.time()\n",
    "    _, global_step_, loss = sess.run([train_step, model.global_step, model.loss],\n",
    "                                     feed_dict={handle: train_handle,\n",
    "                                                model.is_training: True})\n",
    "    if global_step_ % 10 == 0:\n",
    "      clear_output(wait=True)\n",
    "      duration = time.time() - start_time\n",
    "      examples_per_sec = batch_size / float(duration)\n",
    "      epochs = batch_size * global_step_ / float(len(train_data))\n",
    "      print(\"Epochs: {:.2f} global_step: {} loss: {:.3f} ({:.2f} examples/sec; {:.3f} sec/batch)\".format(\n",
    "                epochs, global_step_, loss, examples_per_sec, duration))\n",
    "\n",
    "    if global_step_ % 200 == 0:\n",
    "      # summary\n",
    "      summary_str = sess.run(summary_op, feed_dict={handle: train_handle, model.is_training: False})\n",
    "      train_writer.add_summary(summary_str, global_step=global_step_)\n",
    "\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "    break\n",
    "\n",
    "train_writer.close()\n",
    "print(\"training done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained model\n",
    "\n",
    "* test accuracy: 0.9804 for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_iterator\n",
    "test_iterator = test_dataset.make_one_shot_iterator()\n",
    "test_handle = sess.run(test_iterator.string_handle())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tf.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, acc_op = tf.metrics.accuracy(labels=labels,\n",
    "                                       predictions=model.predictions, name='accuracy')\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "sess.run(acc_op, feed_dict={handle: test_handle, model.is_training: False})\n",
    "print(\"test accuracy:\", sess.run(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "\n",
    "batch_xs = test_data[batch_index]\n",
    "batch_ys = test_labels[batch_index]\n",
    "y_pred = sess.run(model.predictions, feed_dict={images: batch_xs, model.is_training: False})\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  if py == batch_ys[i]:\n",
    "    p.set_title(\"y_pred: {}\".format(py), color='blue')\n",
    "  else:\n",
    "    p.set_title(\"y_pred: {}\".format(py), color='red')\n",
    "  p.imshow(px.reshape(28, 28))\n",
    "  p.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
