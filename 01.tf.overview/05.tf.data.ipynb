{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `tf.data` API\n",
    "\n",
    "* References\n",
    "  * [`tf.data.Dataset` API](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)\n",
    "  * [Importing data](https://www.tensorflow.org/guide/datasets) (Guideline Documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.data` API has two new abstractions\n",
    "* `tf.data.Dataset` represents a sequence of elements, in which each element contains one or more Tensor objects. For example, in an image pipeline, the image data and a label\n",
    "  * Creating a source (e.g. Dataset.from_tensor_slices()) constructs a dataset from one or more `tf.Tensor` objects.\n",
    "    * `tf.data.Dataset.from_tensors()`\n",
    "    * `tf.data.Dataset.from_tensor_slices()`\n",
    "    * `tf.data.TFRecordDataset`:  TFRecord format을 읽을 때\n",
    "  * Applying a transformation (e.g. Dataset.batch()) constructs a dataset from one or more `tf.data.Dataset` objects.\n",
    "* `tf.data.Iterator` provides the main way to extract elements from a dataset. The operation returned by `Iterator.get_next()` yields the next element of a `Dataset` when executed, and typically acts as the interface between input pipeline code and your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST dataset from `tf.keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shot the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 10\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(28, 28))\n",
    "plt.colorbar()\n",
    "#plt.gca().grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set N=50 for small dataset loading\n",
    "N = 50\n",
    "train_data = train_data[:N]\n",
    "train_labels = train_labels[:N]\n",
    "train_data = train_data / 255.\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data[:N]\n",
    "test_labels = test_labels[:N]\n",
    "test_data = test_data / 255.\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input pipeline\n",
    "\n",
    "1. You must define a source. `tf.data.Dataset`.\n",
    "  * To construct a Dataset from some tensors in memory, you can use `tf.data.Dataset.from_tensors()` or `tf.data.Dataset.from_tensor_slices()`.\n",
    "  * Other methods\n",
    "    * `tf.data.TextLineDataset(filenames)`\n",
    "    * `tf.data.FixedLengthRecordDataset(filenames)`\n",
    "    * `tf.data.TFRecordDataset(filenames)`\n",
    "2. Transformation\n",
    "  * `Dataset.map()`: to apply a function to each element\n",
    "  * `Dataset.batch()`\n",
    "  * `Dataset.shuffle()`\n",
    "3. `Iterator`\n",
    "  * `Iterator.initializer`: which enables you to (re)initialize the iterator's state\n",
    "  * `Iterator.get_next()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Store data in `tf.data.Dataset`\n",
    "\n",
    "* `tf.data.Dataset.from_tensor_slices((features, labels))`\n",
    "* `tf.data.Dataset.from_generator(gen, output_types, output_shapes)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((28, 28), ()), types: (tf.float64, tf.int32)>\n",
      "(TensorShape([Dimension(28), Dimension(28)]), TensorShape([]))\n",
      "(tf.float64, tf.int32)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "print(train_dataset)\n",
    "print(train_dataset.output_shapes)\n",
    "print(train_dataset.output_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transformaion\n",
    "\n",
    "* `apply(transformation_func)`\n",
    "* `batch(batch_size)`\n",
    "* `concatenate(dataset)`\n",
    "* `flat_map(map_func)`\n",
    "* `repeat(count=None)`\n",
    "  * count=max_epochs\n",
    "* `shuffle(buffer_size, seed=None, reshuffle_each_iteration=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 10000)\n",
    "train_dataset = train_dataset.repeat(count=2)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Iterator\n",
    "\n",
    "#### 3.1 `make_one_shot_iterator()`\n",
    "\n",
    "* Creates an Iterator for enumerating the elements of this dataset.\n",
    "  * Note: The returned iterator will be initialized automatically. A \"one-shot\" iterator does not currently support re-initialization.\n",
    "\n",
    "###### Common pattern\n",
    "```python\n",
    "while True:\n",
    "  try:\n",
    "    sess.run(result)\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "\n",
    "x, y = train_iterator.get_next()\n",
    "x = tf.cast(x, dtype = tf.float32)\n",
    "y = tf.cast(y, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `for`문으로 epoch control 시 유의점\n",
    "\n",
    "* 사실상 `dataset.repeat(count=2)` 함수로 max_epochs 조절함\n",
    "* `for`문으로 epoch을 조절하고 싶으면 `dataset.repeat()` 쓰지 않으면 됨\n",
    "  * `while`문을 다 돌면 count 만큼의 epochs이 끝남\n",
    "* `for`문으로 control 하고 싶으면 `for`문 시작할 때마다 `iterator.initializer`를 해야 함\n",
    "  * 다음 예제 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  labels: [9 5 3 1 8 0 7 1 4 9 6 3 5 1 0 6]\n",
      "step: 1  labels: [3 9 6 6 9 0 1 9 2 2 3 1 3 8 3 7]\n",
      "step: 2  labels: [8 9 4 3 8 1 0 9 4 4 1 5 2 7 6 5]\n",
      "step: 3  labels: [7 2 1 9 9 1 7 6 9 1 4 4 4 1 4 1]\n",
      "step: 4  labels: [2 7 8 6 2 3 9 7 6 8 9 1 5 0 0 5]\n",
      "step: 5  labels: [8 6 5 3 9 3 9 8 3 3 3 6 2 1 5 7]\n",
      "step: 6  labels: [2 0 0 3]\n",
      "End of dataset\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  #sess.run(iterator.initializer) 할 필요 없음\n",
    "  step = 0\n",
    "  while True:\n",
    "    try:\n",
    "      x_, y_ = sess.run([x, y])\n",
    "\n",
    "      print(\"step: {}  labels: {}\".format(step, y_))\n",
    "      step += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  labels: [2 6 8 7 1 3 1 1 1 5 2 9 7 1 6 7]\n",
      "step: 1  labels: [6 4 3 3 3 8 1 9 3 5 9 5 6 7 3 4]\n",
      "step: 2  labels: [4 2 0 9 0 9 0 8 9 2 9 6 8 0 1 3]\n",
      "step: 3  labels: [4 5 0 1 7 4 7 2 3 3 2 8 1 0 1 5]\n",
      "step: 4  labels: [9 6 3 3 6 5 7 9 6 9 5 9 2 8 3 0]\n",
      "step: 5  labels: [4 4 5 2 3 6 8 1 1 3 0 9 7 1 4 6]\n",
      "step: 6  labels: [1 9 9 8]\n",
      "End of dataset\n",
      "End of dataset\n",
      "End of dataset\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  #sess.run(iterator.initializer) 할 필요 없음\n",
    "  step = 0\n",
    "  max_epochs = 3\n",
    "  for epoch in range(max_epochs):\n",
    "    while True:\n",
    "      try:\n",
    "        x_, y_ = sess.run([x, y])\n",
    "\n",
    "        print(\"step: {}  labels: {}\".format(step, y_))\n",
    "        step += 1\n",
    "\n",
    "      except tf.errors.OutOfRangeError:\n",
    "        print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 `make_initializable_iterator()`\n",
    "\n",
    "* Creates an Iterator for enumerating the elements of this dataset.\n",
    "* Should `run` the `iterator.initializer`.\n",
    "\n",
    "사용법\n",
    "```python\n",
    "dataset = ...\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "# ...\n",
    "sess.run(iterator.initializer)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "\n",
    "x, y = train_iterator.get_next()\n",
    "x = tf.cast(x, dtype = tf.float32)\n",
    "y = tf.cast(y, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `for`문으로 epoch control 시 유의점\n",
    "\n",
    "* `iterator.initializer`를 통해서 매 `for`문 마다 dataset을 initial 해야함\n",
    "* `N / batch_size`가 나누어 떨어지지 않으면 맨 마지막 배치는 `N % batch_size` 만큼의 데이터만 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  labels: [0 3 8 6 3 8 9 1 0 4 8 0 1 9 2 1]\n",
      "step: 1  labels: [0 5 4 7 8 9 7 5 1 4 7 6 2 1 3 3]\n",
      "step: 2  labels: [3 6 2 9 6 5 3 7 5 6 1 3 4 1 9 9]\n",
      "step: 3  labels: [9 2 4 5 9 8 1 0 3 2 7 1 0 4 3 9]\n",
      "step: 4  labels: [3 2 1 6 5 4 9 6 8 7 8 0 0 5 5 3]\n",
      "step: 5  labels: [2 2 1 4 7 6 3 1 6 9 9 1 6 9 1 9]\n",
      "step: 6  labels: [8 3 7 3]\n",
      "End of dataset\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  sess.run(train_iterator.initializer)\n",
    "  step = 0\n",
    "  while True:\n",
    "    try:\n",
    "      x_, y_ = sess.run([x, y])\n",
    "\n",
    "      print(\"step: {}  labels: {}\".format(step, y_))\n",
    "      step += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  labels: [6 2 0 3 1 0 9 5 5 2 1 1 4 6 7 2]\n",
      "step: 1  labels: [5 4 3 3 8 8 2 8 5 9 9 9 6 4 7 0]\n",
      "step: 2  labels: [9 9 1 9 4 1 0 6 7 7 3 8 1 6 3 3]\n",
      "step: 3  labels: [3 1 0 7 9 1 8 1 3 4 1 9 6 6 2 4]\n",
      "step: 4  labels: [1 3 8 3 8 2 7 2 7 4 3 2 9 3 5 8]\n",
      "step: 5  labels: [6 6 5 7 9 4 9 6 0 5 1 9 0 9 3 1]\n",
      "step: 6  labels: [0 1 3 5]\n",
      "End of dataset\n",
      "step: 7  labels: [0 1 7 7 9 9 5 6 2 9 3 9 3 2 8 7]\n",
      "step: 8  labels: [3 6 3 1 2 7 4 0 8 0 6 6 2 1 1 5]\n",
      "step: 9  labels: [8 3 8 5 4 4 9 4 1 9 5 1 3 6 3 1]\n",
      "step: 10  labels: [9 0 2 9 4 2 5 6 7 3 3 4 1 1 6 4]\n",
      "step: 11  labels: [7 6 1 0 9 5 8 3 1 9 3 8 1 9 6 1]\n",
      "step: 12  labels: [2 3 2 0 5 8 6 7 4 1 0 9 5 8 3 7]\n",
      "step: 13  labels: [0 3 9 9]\n",
      "End of dataset\n",
      "step: 14  labels: [5 1 9 4 9 2 5 7 4 7 1 3 0 8 0 3]\n",
      "step: 15  labels: [3 1 3 0 6 8 4 8 2 7 5 4 3 6 7 2]\n",
      "step: 16  labels: [9 9 3 2 1 5 8 6 6 9 1 3 0 6 9 1]\n",
      "step: 17  labels: [1 9 4 6 5 9 9 6 0 7 5 9 1 6 7 2]\n",
      "step: 18  labels: [8 9 0 3 6 6 1 5 8 8 2 4 3 2 1 1]\n",
      "step: 19  labels: [8 3 1 4 3 0 9 0 7 4 2 3 9 1 3 1]\n",
      "step: 20  labels: [9 3 5 7]\n",
      "End of dataset\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "  step = 0\n",
    "  max_epochs = 3\n",
    "  for epoch in range(max_epochs):\n",
    "    sess.run(train_iterator.initializer)\n",
    "    while True:\n",
    "      try:\n",
    "        x_, y_ = sess.run([x, y])\n",
    "\n",
    "        print(\"step: {}  labels: {}\".format(step, y_))\n",
    "        step += 1\n",
    "\n",
    "      except tf.errors.OutOfRangeError:\n",
    "        print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [From TensorFlow official site](https://www.tensorflow.org/programmers_guide/datasets)\n",
    "\n",
    "* 밑에 예제들은 TF 홈페이지에서 가져옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "(10,)\n",
      "(tf.float32, tf.int32)\n",
      "(TensorShape([]), TensorShape([Dimension(100)]))\n",
      "(tf.float32, (tf.float32, tf.int32))\n",
      "(TensorShape([Dimension(10)]), (TensorShape([]), TensorShape([Dimension(100)])))\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))\n",
    "print(dataset1.output_types)  # ==> \"tf.float32\"\n",
    "print(dataset1.output_shapes)  # ==> \"(10,)\"\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "   (tf.random_uniform([4]),\n",
    "    tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
    "print(dataset2.output_types)  # ==> \"(tf.float32, tf.int32)\"\n",
    "print(dataset2.output_shapes)  # ==> \"((), (100,))\"\n",
    "\n",
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "print(dataset3.output_types)  # ==> (tf.float32, (tf.float32, tf.int32))\n",
    "print(dataset3.output_shapes)  # ==> \"(10, ((), (100,)))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': tf.float32, 'b': tf.int32}\n",
      "{'a': TensorShape([]), 'b': TensorShape([Dimension(100)])}\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "   {\"a\": tf.random_uniform([4]),\n",
    "    \"b\": tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)})\n",
    "print(dataset.output_types)  # ==> \"{'a': tf.float32, 'b': tf.int32}\"\n",
    "print(dataset.output_shapes)  # ==> \"{'a': (), 'b': (100,)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(100)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  for i in range(10):\n",
    "    value = sess.run(next_element)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(max_value)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Initialize an iterator over a dataset with 10 elements.\n",
    "  sess.run(iterator.initializer, feed_dict={max_value: 10})\n",
    "  for i in range(10):\n",
    "    value = sess.run(next_element)\n",
    "    print(value)\n",
    "\n",
    "  # Initialize the same iterator over a dataset with 100 elements.\n",
    "  sess.run(iterator.initializer, feed_dict={max_value: 100})\n",
    "  for i in range(100):\n",
    "    value = sess.run(next_element)\n",
    "    print(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
